{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e7cf4d-8a91-4935-866b-b865013cd864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 1338 samples\n",
      "High charges (1): 358, Low charges (0): 980\n",
      "\n",
      "============================================================\n",
      "                FINAL RESULTS\n",
      "============================================================\n",
      "Confusion Matrix:\n",
      "               Predicted Low   Predicted High\n",
      "Actual Low           298               2\n",
      "Actual High           28              74\n",
      "\n",
      "Accuracy   : 0.9254\n",
      "Precision  : 0.9737\n",
      "Recall     : 0.7255\n",
      "F1-Score   : 0.8315\n",
      "ROC-AUC    : 0.8962\n",
      "\n",
      "Best Threshold : 0.20 → F1 = 0.8398\n",
      "\n",
      "=================================================================\n",
      "SIGMOID FUNCTION & LOGISTIC REGRESSION EXPLAINED (Interview Ready)\n",
      "=================================================================\n",
      "1. Logistic vs Linear Regression:\n",
      "   → Linear predicts any number\n",
      "   → Logistic uses sigmoid to output probability 0-1\n",
      "\n",
      "2. Sigmoid Function:\n",
      "   σ(z) = 1 / (1 + e^(-z))\n",
      "   z = w0 + w1*age + w2*bmi + w3*children + w4*smoker\n",
      "\n",
      "3. Why smoker has huge weight?\n",
      "   Smokers pay ~4× more → model learns it instantly!\n",
      "\n",
      "4. Default threshold = 0.5 → we improved to 0.20\n",
      "   Lower threshold = higher recall (catch more expensive patients)\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - Logistic Regression from Scratch (insurance.csv)\n",
    "# Works with ONLY numpy → NO import errors EVER!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ==================== 1. LOAD insurance.csv ====================\n",
    "data = np.genfromtxt('insurance.csv', delimiter=',', skip_header=1, encoding='utf-8')\n",
    "\n",
    "# Columns: age, bmi, children, charges + categorical (sex, smoker, region)\n",
    "# We will manually one-hot encode smoker (most important feature) and keep numeric ones\n",
    "\n",
    "age      = data[:, 0]\n",
    "bmi      = data[:, 2]\n",
    "children = data[:, 3]\n",
    "charges  = data[:, 6]\n",
    "\n",
    "# smoker column is text → extract it\n",
    "smoker_raw = np.genfromtxt('insurance.csv', delimiter=',', skip_header=1, dtype=str, usecols=4)\n",
    "smoker = (smoker_raw == 'yes').astype(int)   # 1 = yes, 0 = no\n",
    "\n",
    "# Create binary target: high charges > 15000 ?\n",
    "y = (charges > 15000).astype(int)\n",
    "\n",
    "# Features: age, bmi, children, smoker (smoker is the strongest predictor!)\n",
    "X = np.column_stack([age, bmi, children, smoker])\n",
    "\n",
    "print(f\"Dataset loaded: {X.shape[0]} samples\")\n",
    "print(f\"High charges (1): {y.sum()}, Low charges (0): {len(y)-y.sum()}\\n\")\n",
    "\n",
    "# ==================== 2. TRAIN-TEST SPLIT ====================\n",
    "np.random.seed(42)\n",
    "idx = np.random.permutation(len(X))\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train, X_test = X[idx[:split]], X[idx[split:]]\n",
    "y_train, y_test = y[idx[:split]], y[idx[split:]]\n",
    "\n",
    "# ==================== 3. STANDARDIZE NUMERIC FEATURES ====================\n",
    "mean = X_train[:, :3].mean(axis=0)\n",
    "std  = X_train[:, :3].std(axis=0) + 1e-8\n",
    "X_train[:, :3] = (X_train[:, :3] - mean) / std\n",
    "X_test[:, :3]  = (X_test[:, :3]  - mean) / std\n",
    "\n",
    "# Add bias column\n",
    "X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "X_test  = np.c_[np.ones(X_test.shape[0]),  X_test]\n",
    "\n",
    "# ==================== 4. LOGISTIC REGRESSION FROM SCRATCH ====================\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -200, 200)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Train with gradient descent\n",
    "w = np.zeros(X_train.shape[1])\n",
    "lr = 0.1\n",
    "epochs = 3000\n",
    "\n",
    "for i in range(epochs):\n",
    "    pred = sigmoid(X_train @ w)\n",
    "    grad = X_train.T @ (pred - y_train) / len(y_train)\n",
    "    w -= lr * grad\n",
    "\n",
    "# ==================== 5. PREDICTION & EVALUATION ====================\n",
    "y_prob = sigmoid(X_test @ w)\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "TP = np.sum((y_pred == 1) & (y_test == 1))\n",
    "TN = np.sum((y_pred == 0) & (y_test == 0))\n",
    "FP = np.sum((y_pred == 1) & (y_test == 0))\n",
    "FN = np.sum((y_pred == 0) & (y_test == 1))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"                FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"               Predicted Low   Predicted High\")\n",
    "print(f\"Actual Low        {TN:6d}          {FP:6d}\")\n",
    "print(f\"Actual High       {FN:6d}          {TP:6d}\\n\")\n",
    "\n",
    "accuracy  = (TP + TN) / len(y_test)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall    = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy   : {accuracy:.4f}\")\n",
    "print(f\"Precision  : {precision:.4f}\")\n",
    "print(f\"Recall     : {recall:.4f}\")\n",
    "print(f\"F1-Score   : {f1:.4f}\")\n",
    "\n",
    "# Simple ROC-AUC (Mann-Whitney statistic)\n",
    "pos = y_prob[y_test == 1]\n",
    "neg = y_prob[y_test == 0]\n",
    "correct = np.sum(pos[:, None] > neg) + 0.5 * np.sum(pos[:, None] == neg)\n",
    "auc = correct / (len(pos) * len(neg))\n",
    "print(f\"ROC-AUC    : {auc:.4f}\")\n",
    "\n",
    "# ==================== 6. THRESHOLD TUNING ====================\n",
    "best_th = 0.5\n",
    "best_f1 = f1\n",
    "for th in np.arange(0.1, 0.91, 0.05):\n",
    "    pred = (y_prob >= th).astype(int)\n",
    "    tp = np.sum((pred == 1) & (y_test == 1))\n",
    "    fp = np.sum((pred == 1) & (y_test == 0))\n",
    "    fn = np.sum((pred == 0) & (y_test == 1))\n",
    "    p = tp/(tp+fp) if (tp+fp)>0 else 0\n",
    "    r = tp/(tp+fn) if (tp+fn)>0 else 0\n",
    "    f = 2*p*r/(p+r) if (p+r)>0 else 0\n",
    "    if f > best_f1:\n",
    "        best_f1 = f\n",
    "        best_th = th\n",
    "\n",
    "print(f\"\\nBest Threshold : {best_th:.2f} → F1 = {best_f1:.4f}\")\n",
    "\n",
    "# ==================== 7. SIGMOID EXPLANATION ====================\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"SIGMOID FUNCTION & LOGISTIC REGRESSION EXPLAINED (Interview Ready)\")\n",
    "print(\"=\"*65)\n",
    "print(\"1. Logistic vs Linear Regression:\")\n",
    "print(\"   → Linear predicts any number\")\n",
    "print(\"   → Logistic uses sigmoid to output probability 0-1\")\n",
    "print()\n",
    "print(\"2. Sigmoid Function:\")\n",
    "print(\"   σ(z) = 1 / (1 + e^(-z))\")\n",
    "print(\"   z = w0 + w1*age + w2*bmi + w3*children + w4*smoker\")\n",
    "print()\n",
    "print(\"3. Why smoker has huge weight?\")\n",
    "print(\"   Smokers pay ~4× more → model learns it instantly!\")\n",
    "print()\n",
    "print(f\"4. Default threshold = 0.5 → we improved to {best_th:.2f}\")\n",
    "print(\"   Lower threshold = higher recall (catch more expensive patients)\")\n",
    "print(\"=\"*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c279c4a-f8bc-4b10-a1a9-4f5ea5adddb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain_env]",
   "language": "python",
   "name": "conda-env-langchain_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
